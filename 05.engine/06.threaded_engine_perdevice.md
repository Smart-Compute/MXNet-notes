## ThreadedEnginePerDevice
* 支持三类共五个队列：cpu优先级/普通队列、gpu优先级/普通队列、gpu io copy队列；
* 每个队列都绑定一个线程池；
* 支持设置环境变量MXNET_CPU_WORKER_NTHREADS、MXNET_GPU_WORKER_NTHREADS、MXNET_GPU_COPY_NTHREADS；
* omp设置优先级：OMP_NUM_THREADS > MXNET_OMP_MAX_THREADS；
```c++
class ThreadedEnginePerDevice : public ThreadedEngine {
 public:
  static auto constexpr kFIFO = dmlc::ConcurrentQueueType::kFIFO;
  static auto constexpr kPriority = dmlc::ConcurrentQueueType::kPriority;
  /* 支持三类共五个队列：cpu优先级/普通队列、gpu优先级/普通队列、gpu io copy队列； */
  static auto constexpr kCopyQueue = kPriority; // 支持优先级调度
  static auto constexpr kPriorityQueue = kPriority; // 优先级调度
  static auto constexpr kWorkerQueue = kFIFO; // 常规task队列为FIFO类型

  ThreadedEnginePerDevice() noexcept(false) { this->Start(); }
  ~ThreadedEnginePerDevice() noexcept(false) { this->StopNoWait(); }

  void Start() override {
    if (is_worker_) return; // 工作线程不能调用，防止出错
    /* 获取 MXNET_GPU_WORKER_NTHREADS */
    gpu_worker_nthreads_ = common::GetNumThreadsPerGPU(); // 默认为2个
    cpu_worker_nthreads_ = dmlc::GetEnv("MXNET_CPU_WORKER_NTHREADS", 1);
    gpu_copy_nthreads_ = dmlc::GetEnv("MXNET_GPU_COPY_NTHREADS", 2);
    /* 创建cpu_priority_worker_，其他worker会按需延迟创建 */
    int cpu_priority_nthreads = dmlc::GetEnv("MXNET_CPU_PRIORITY_NTHREADS", 4);
    cpu_priority_worker_.reset(new ThreadWorkerBlock<kPriorityQueue>());
    cpu_priority_worker_->pool.reset(new ThreadPool(
        cpu_priority_nthreads,
        [this](std::shared_ptr<dmlc::ManualEvent> ready_event) {
          this->CPUWorker(Context(), cpu_priority_worker_.get(), ready_event);
        }, true)); // 等待线程启动
  }
  void StopNoWait() {
    SignalQueuesForKill(); // 清空队列
    /* 关闭线程池/删除队列 */
    gpu_normal_workers_.Clear();
    gpu_priority_workers_.Clear();
    gpu_copy_workers_.Clear();
    cpu_normal_workers_.Clear();
    cpu_priority_worker_.reset(nullptr);
  }
  void Stop() override {
    if (is_worker_) return; // 工作线程不能调用，防止出错
    WaitForAll(); // 等待所有pending op执行完毕
    StopNoWait(); // 关闭引擎
  }

 protected:
  void PushToExecute(OprBlock *opr_block, bool pusher_thread) override {
    /* 支持cpu/gpu 优先级队列/常规队列及io copy队列调度，优先执行kDeleteVar */
    const Context& ctx = opr_block->ctx;
    if ((opr_block->opr->prop == FnProperty::kAsync ||
         opr_block->opr->prop == FnProperty::kDeleteVar) && pusher_thread) {
      if (ctx.dev_mask() == Context::kGPU) {
        #if MXNET_USE_CUDA
        MSHADOW_CATCH_ERROR(mshadow::SetDevice<gpu>(ctx.dev_id));
        #endif
      }
      // push时，依赖均已解除，pusher线程立即执行 kAsync/kDeleteVar op
      this->ExecuteOprBlock(RunContext{ctx, nullptr, nullptr, false}, opr_block);
    } else {
      if (ctx.dev_mask() == Context::kCPU) { // CPU task
        if (opr_block->opr->prop == FnProperty::kCPUPrioritized) {
          // push到cpu优先级队列，start时已创建线程池
          cpu_priority_worker_->task_queue.Push(opr_block, opr_block->priority);
        } else {
          int dev_id = ctx.dev_id;
          int nthread = cpu_worker_nthreads_;
          auto ptr = // 延迟创建cpu常规task线程池及队列
          cpu_normal_workers_.Get(dev_id, [this, ctx, nthread]() {
              auto blk = new ThreadWorkerBlock<kWorkerQueue>();
              blk->pool.reset(new ThreadPool(nthread,
                  [this, ctx, blk](std::shared_ptr<dmlc::ManualEvent> ready_event) {
                    this->CPUWorker(ctx, blk, ready_event);
                  }, true)); // 等待线程启动
            return blk;
          });
          if (ptr) {
            if (opr_block->opr->prop == FnProperty::kDeleteVar) {
              // push到队首，优先执行 kDeleteVar
              ptr->task_queue.PushFront(opr_block, opr_block->priority);
            } else {
              ptr->task_queue.Push(opr_block, opr_block->priority);
            }
          }
        }
      } else { // GPU task
        CHECK_EQ(ctx.dev_mask(), Context::kGPU);
        const FnProperty prop = opr_block->opr->prop;
        const bool is_copy = (prop == FnProperty::kCopyFromGPU ||
                              prop == FnProperty::kCopyToGPU);
        if (is_copy) { // io copy task
          const size_t nthread = gpu_copy_nthreads_;
          auto ptr = gpu_copy_workers_.Get(ctx.dev_id, [this, ctx, is_copy, nthread]() {
            // Signify to kernel that GPU is being used, so reserve cores as necessary
            OpenMP::Get()->set_reserve_cores(GetReserveCoreCount(true));
            auto blk = new ThreadWorkerBlock<kCopyQueue>();
              blk->pool.reset(new ThreadPool(
                nthread,
                [this, ctx, is_copy, blk]
                  (std::shared_ptr<dmlc::ManualEvent> ready_event) {
                    this->GPUWorker(ctx, is_copy, blk, ready_event);
                  }, true)); // 等待线程启动
              return blk;
            }); // 延迟创建gpu copy task线程池及队列
          if (ptr) {
            if (opr_block->opr->prop == FnProperty::kDeleteVar) {
              // is_copy 与 kDeleteVar 互斥，走不到这里
              ptr->task_queue.PushFront(opr_block, opr_block->priority);
            } else {
              ptr->task_queue.Push(opr_block, opr_block->priority);
            }
          }
        } else { // GPU 计算task
          const size_t nthread = gpu_worker_nthreads_;
          if (opr_block->opr->prop == FnProperty::kGPUPrioritized) {
            // push到gpu优先级队列，此处延迟创建线程池及队列
            auto ptr = gpu_priority_workers_.Get(ctx.dev_id, [this, ctx, is_copy, nthread]() {
              // Signify to kernel that GPU is being used, so reserve cores as necessary
              OpenMP::Get()->set_reserve_cores(GetReserveCoreCount(true));
                auto blk = new ThreadWorkerBlock<kPriorityQueue>();
                blk->pool.reset(new ThreadPool(
                  nthread,
                  [this, ctx, is_copy, blk]
                    (std::shared_ptr<dmlc::ManualEvent> ready_event) {
                      this->GPUWorker(ctx, is_copy, blk, ready_event);
                    }, true)); // 等待线程启动
                return blk;
            });
            if (ptr) { // push
              ptr->task_queue.Push(opr_block, opr_block->priority);
            }
          } else {
            // 延迟创建gpu常规task线程池及队列
            auto ptr = gpu_normal_workers_.Get(ctx.dev_id, [this, ctx, is_copy, nthread]() {
              // Signify to kernel that GPU is being used, so reserve cores as necessary
              OpenMP::Get()->set_reserve_cores(GetReserveCoreCount(true));
                auto blk = new ThreadWorkerBlock<kWorkerQueue>();
                blk->pool.reset(new ThreadPool(
                  nthread,
                  [this, ctx, is_copy, blk]
                    (std::shared_ptr<dmlc::ManualEvent> ready_event) {
                      this->GPUWorker(ctx, is_copy, blk, ready_event);
                    }, true)); // 等待线程启动
                return blk;
            });
            if (ptr) {
              if (opr_block->opr->prop == FnProperty::kDeleteVar) {
                // push到队首，优先执行 kDeleteVar
                ptr->task_queue.PushFront(opr_block, opr_block->priority);
              } else {
                ptr->task_queue.Push(opr_block, opr_block->priority);
              }
            }
          }
        }
      }
    }
  }

 private:
  template<dmlc::ConcurrentQueueType type>
  struct ThreadWorkerBlock {
    dmlc::ConcurrentBlockingQueue<OprBlock*, type>  task_queue; // 任务队列
    std::unique_ptr<ThreadPool> pool; // task线程池

    ThreadWorkerBlock() = default;
    ~ThreadWorkerBlock() noexcept(false) {}
  };

  static MX_THREAD_LOCAL bool is_worker_; // 线程级别变量

  size_t cpu_worker_nthreads_;
  size_t gpu_worker_nthreads_;
  size_t gpu_copy_nthreads_;

  common::LazyAllocArray<ThreadWorkerBlock<kWorkerQueue> > cpu_normal_workers_;
  std::unique_ptr<ThreadWorkerBlock<kPriorityQueue> > cpu_priority_worker_;
  common::LazyAllocArray<ThreadWorkerBlock<kWorkerQueue> > gpu_normal_workers_;
  common::LazyAllocArray<ThreadWorkerBlock<kPriorityQueue> > gpu_priority_workers_;
  common::LazyAllocArray<ThreadWorkerBlock<kCopyQueue> > gpu_copy_workers_;

  template<dmlc::ConcurrentQueueType type>
  inline void CPUWorker(Context ctx,
                        ThreadWorkerBlock<type> *block,
                        const std::shared_ptr<dmlc::ManualEvent>& ready_event) {
    this->is_worker_ = true; // 工作线程标记，线程级别数据
    auto* task_queue = &(block->task_queue);
    RunContext run_ctx{ctx, nullptr, nullptr, false};

    OprBlock* opr_block;
    ready_event->signal(); // 线程ready
    // 兼容 OMP_NUM_THREADS，支持 MXNET_OMP_MAX_THREADS；
    OpenMP::Get()->on_start_worker_thread(true);

    while (task_queue->Pop(&opr_block)) { // 从队列拿任务执行
      this->ExecuteOprBlock(run_ctx, opr_block);
    }
  }

  template<dmlc::ConcurrentQueueType type>
  inline void GPUWorker(Context ctx,
                        bool is_copy_worker,
                        ThreadWorkerBlock<type> *block,
                        const std::shared_ptr<dmlc::ManualEvent>& ready_event) {
    this->is_worker_ = true; // 工作线程标记，线程级别数据
#if MXNET_USE_CUDA
    // GPU代码待注解
    CHECK(block != nullptr);
    mshadow::Stream<gpu> *stream = nullptr;
    GPUAuxStream *aux_stream = nullptr;
    do {
      ThreadPool::SetReadyOnDestroy setReady(ready_event);
      // allocate stream
      mshadow::SetDevice<gpu>(ctx.dev_id);
      if (is_copy_worker) {
        stream = mshadow::NewStream<gpu>(false, false, ctx.dev_id);
      } else {
        stream = mshadow::NewStream<gpu>(true, MXNET_USE_CUDNN != 0, ctx.dev_id);
        aux_stream = new GPUAuxStream(stream);
      }
    } while (false);
    // execute task
    OprBlock* opr_block;
    RunContext run_ctx{ctx, stream, aux_stream, false};
    auto* task_queue = &(block->task_queue);

    // Don't eat up omp threads for GPU jobs.  They're probably best used elsewhere,
    // for example for image decoding or the optimizer pass
    OpenMP::Get()->on_start_worker_thread(false);

    while (task_queue->Pop(&opr_block)) {
      this->ExecuteOprBlock(run_ctx, opr_block);
    }
    // Catch exception for CUDA driver shutdown
    MSHADOW_CATCH_ERROR(mshadow::DeleteStream<gpu>(stream));
    if (aux_stream != nullptr)
      delete aux_stream;
#else
    ready_event->signal(); // 直接退出线程
#endif
  }

  int GetReserveCoreCount(const bool using_gpu) const {
    int reserve = 0;
    if (using_gpu) {
      ++reserve;
      if (OpenMP::Get()->GetRecommendedOMPThreadCount(true) >= 8) {
        ++reserve;
      }
    }
    return reserve;
  }

  void SignalQueuesForKill() {
    SignalQueueForKill(&gpu_priority_workers_);
    SignalQueueForKill(&gpu_normal_workers_);
    SignalQueueForKill(&gpu_copy_workers_);
    SignalQueueForKill(&cpu_normal_workers_);
    if (cpu_priority_worker_) {
      cpu_priority_worker_->task_queue.SignalForKill();
    }
  }
  template<typename Object>
  static inline void SignalQueueForKill(common::LazyAllocArray<Object> *array) {
    array->ForEach([](size_t i, Object *block) {
      block->task_queue.SignalForKill();
    });
  }
};

MX_THREAD_LOCAL bool ThreadedEnginePerDevice::is_worker_ = false;
```
