## InferShape
* 加载初始值及输入配置，迭代遍历节点，infer shape/dtype/stype；
* 尝试从var节点的__shape__属性中读入shape；
* backward op的输入/输出梯度的shape和其相应forward op的输出/输入shape保持一致；
* forward op根据已知的input和output shapes推演(infer)未知shapes；
* infer stype时，会额外infer节点的dispatch mode；
```c++
template<typename AttrType>
using FInferNodeEntryAttr = std::function<bool (const NodeAttrs& attrs,
                                                std::vector<AttrType> *in_attrs,
                                                std::vector<AttrType> *out_attrs)>;
using FInferShape = FInferNodeEntryAttr<TShape>;
using FInferType = FInferNodeEntryAttr<int>;
using FInferStorageType = std::function<bool (const NodeAttrs& attrs,        // 节点属性配置
                                              const int dev_mask,            // 节点设备类型       
                                              DispatchMode* dispatch_mode,   // 节点dispatch mode
                                              std::vector<int>* in_attrs,    // 输入属性
                                              std::vector<int>* out_attrs)>; // 输出属性
template<typename ValueType>
using NodeEntryMap = std::unordered_map<NodeEntry, ValueType, NodeEntryHash, NodeEntryEqual>;

/* 对infer函数进行封装: infer shape/dtype调用 */
template<typename AttrType, typename FInfer>
bool ApplyOpInferAttr(const nnvm::Graph& g,
                      const FInfer& finfer,
                      const NodeAttrs& attrs,
                      const uint32_t nid,
                      std::vector<AttrType>* in_attrs,
                      std::vector<AttrType>* out_attrs,
                      DispatchMode* dispatch_mode) { 
  return finfer(attrs, in_attrs, out_attrs);
}
/* infer stype的特化版本 */
template<>    
bool ApplyOpInferAttr<int, FInferStorageType>(const nnvm::Graph& g,
                                              const FInferStorageType& finfer,
                                              const NodeAttrs& attrs,
                                              const uint32_t nid,
                                              std::vector<int>* in_attrs,
                                              std::vector<int>* out_attrs,
                                              DispatchMode* dispatch_mode) {
  /* 获取节点设备类型配置：cpu or gpu */
  const DevMaskVector& dev_masks = g.GetAttr<DevMaskVector>("dev_mask");
  /* 除了传入atrrs/in_atrrs/out_attrs外，还传入当前节点设备类型和当前节点的dispatch mode；*/
  const bool success = finfer(attrs, dev_masks[nid], dispatch_mode, in_attrs, out_attrs);
  if (!success) {
    LOG(FATAL) << "Operator not implemented: "
               << common::operator_stype_string(attrs, dev_masks[nid], *in_attrs, *out_attrs);
  }
  if (*dispatch_mode == DispatchMode::kFComputeFallback) {
    /* 如果dispatch mode命中fallback时，打印warning日志 */
    common::LogStorageFallback(attrs, dev_masks[nid], in_attrs, out_attrs);
  }
  return true;
}

template<typename AttrType, typename FInferType, typename IsNone, typename FDefault>
nnvm::Graph InferAttr(nnvm::Graph &&ret,         // infer该计算图的属性；
                      const AttrType empty_val,  // 空属性值(默认/待infer)
                      const char* infer_name,    // infer函数，如：FInferShape；
                      const char* input_name,    // input节点属性，如：shape_inputs；
                      const char* attr_key_name, // (var节点)属性名，如：shape_attr_key(__shape__)；
                      const char* attr_name,     // (图)属性，如：shape；
                      const char* unknown_name,  // 输出属性未知节点数，如：shape_num_unknown_nodes；
                      IsNone fis_none,           // 判断属性值是否已知(无需infer)
                      FDefault fdefault,         // 默认infer函数，op未提供时使用
                      bool bwd_identity_assign,  // 开启backward infer，infer stype时为false；
                      const char* dispatch_mode_name, // 节点的dispatch mode属性名
                      const DispatchMode default_mode_val = DispatchMode::kUndefined) {
  using AttrVector = std::vector<AttrType>;
  using NodeAttrVector = std::vector<DispatchMode>;

  const IndexedGraph& idx = ret.indexed_graph();
  // (shape)infer函数，如：FInferNodeEntryAttr<TShape>
  static auto& finfer_shape = Op::GetAttr<FInferType>(infer_name);
  static auto& is_backward = Op::GetAttr<TIsBackward>("TIsBackward");
  // gradient function, used to get node correspondence.
  static auto& fgrad = Op::GetAttr<FGradient>("FGradient");

  AttrVector rshape; // 获取shape初始值、设置input节点shape、设置shape_hints
  if (ret.attrs.count(attr_name) != 0) { // 获取图当前的shape配置作为初始值
    rshape = ret.MoveCopyAttr<AttrVector>(attr_name);
  } else { // 初始化为空置
    rshape.resize(idx.num_node_entries(), empty_val);
  }
  if (ret.attrs.count(input_name) != 0) { // 遍历input节点并设置shape
    const AttrVector& shape_args = ret.GetAttr<AttrVector>(input_name);
    CHECK_LE(shape_args.size(), idx.input_nodes().size())
        << "More provided " << attr_name << "s than number of arguments.";
    for (size_t i = 0; i < shape_args.size(); ++i) { // 通过下标匹配
      rshape[idx.entry_id(idx.input_nodes()[i], 0)] = shape_args[i];
    }
  }
  std::string shape_hints_key = std::string(attr_name) + "_hints";
  if (ret.attrs.count(shape_hints_key)) { // 从shape_hints获取配置
    NodeEntryMap<AttrType> shape_hints =
      ret.GetAttr<NodeEntryMap<AttrType>>(shape_hints_key);
    for (const auto& kv : shape_hints) { // 遍历map
      NodeEntry e = kv.first;
      if (idx.exist(e.node.get())) { // node属于图，设置属性
        rshape[idx.entry_id(kv.first)] = kv.second;
      }
    }
  }
  std::string shape_attr_key; // 从图属性获取(节点)属性名用于获取节点属性值
  if (ret.attrs.count(attr_key_name) != 0) {
    shape_attr_key = ret.GetAttr<std::string>(attr_key_name);
    ret.attrs.erase(attr_key_name);
  }

  uint32_t node_start = 0, node_end = idx.num_nodes();
  if (ret.attrs.count("node_range")) { // 获取infer节点区间，默认全部节点
    const auto& range = ret.GetAttr<std::pair<uint32_t, uint32_t> >("node_range");
    node_start = range.first; node_end = range.second;
    CHECK_GE(node_start, 0); CHECK_LE(node_end, idx.num_nodes());
    ret.attrs.erase("node_range");
  }
  uint32_t entry_start = 0, entry_end = idx.num_node_entries();
  if (ret.attrs.count("entry_range")) { // 获取节点输出(NDArray)区间
    const auto& range = ret.GetAttr<std::pair<uint32_t, uint32_t> >("entry_range");
    entry_start = range.first; entry_end = range.second;
    CHECK_GE(entry_start, 0); CHECK_LE(entry_end, idx.num_node_entries());
    ret.attrs.erase("entry_range");
  }

  DispatchModeVector dispatch_modes; // dispatch mode数组(infer storage type使用)
  if (dispatch_mode_name != nullptr) {
    if (ret.attrs.count(dispatch_mode_name) != 0) {
      dispatch_modes = ret.MoveCopyAttr<NodeAttrVector>(dispatch_mode_name);
    } else {
      LOG(FATAL) << "Node attribute " << dispatch_mode_name << " does not exist in the graph";
    }
  }

  std::vector<AttrType> ishape, oshape;
 
  auto infer_step = [&](uint32_t nid, bool last_iter) {
    const auto& inode = idx[nid];
    const uint32_t num_inputs = inode.inputs.size();
    const uint32_t num_outputs = inode.source->num_outputs();
    if (inode.source->is_variable()) {
      CHECK(inode.source->op() == nullptr); // var节点无op
      CHECK_EQ(num_outputs, 1U); // var节点一个输出，即自己
      const uint32_t out_ent_id = idx.entry_id(nid, 0); // 获取entry_id
      /* 当节点shape未知时，尝试从节点属性(__shape__)获取值 */
      if (shape_attr_key.length() != 0 && fis_none(rshape[out_ent_id])) {
        auto it = inode.source->attrs.dict.find(shape_attr_key); // 获取节点配置
        if (it != inode.source->attrs.dict.end()) {
          std::istringstream is(it->second); // 从节点__shape__属性中读入shape
          CHECK(is >> rshape[out_ent_id]) << "Invalid attribute";
        }
      }
      if (dispatch_mode_name != nullptr) { // 为节点分配默认值 DispatchMode::kVariable
        op::dispatch_mode_assign(&dispatch_modes[nid], default_mode_val);
      }
    } else if (is_backward.get(inode.source->op(), false) &&
               inode.control_deps.size() && bwd_identity_assign) {
      /* infer shape/dtype时，bwd_identity_assign为true；infer stype时，为false；*/
      CHECK(dispatch_mode_name == nullptr) // backward infer不支持stype
        << "Backward inference for node attributes is not available";
      CHECK_GE(inode.control_deps.size(), 1U) // backward节点至少依赖其对应的forward节点
        << "BackwardOp need to have control_deps to its forward op";
      const IndexedGraph::Node& fnode = idx[inode.control_deps[0]];
      NodePtr fwd_ptr = inode.source->control_deps[0]; // forward节点必须为op节点
      CHECK(fwd_ptr->op() != nullptr) << "Forward op cannot be a variable";
      /* 构造FGradient函数的输入 */
      std::vector<NodeEntry> ograd(fwd_ptr->num_outputs());
      for (size_t i = 0; i < ograd.size(); ++i) {
        /* 设置node为nullptr，用来识别当前backward节点inputs中的梯度变量 */
        ograd[i].index = static_cast<uint32_t>(i);
      }
      /* 调用FGradient，获取backward的输出梯度 */
      auto igrad = fgrad[fwd_ptr->op()](fwd_ptr, ograd);
      const Node* igrad_node = nullptr;
      /* infer backward节点输出梯度(igrad)的shape */
      for (size_t i = 0; i < igrad.size(); ++i) {
        if (igrad[i].node->op() == inode.source->op()) { // 此处判断是否多余？
          uint32_t eid = idx.entry_id(nid, igrad[i].index); // 当前节点输出
          if (fis_none(rshape[eid])) { // fgrad函数无法infer igrad[i]的shape
            // backward输出梯度的shape默认和forward相应的输入保持一致(可能也为none)
            rshape[eid] = rshape[idx.entry_id(fnode.inputs[i])];
          } else if (!fis_none(rshape[idx.entry_id(fnode.inputs[i])])) {
            // backward输出梯度的shape一致性检查
            CHECK_EQ(rshape[eid], rshape[idx.entry_id(fnode.inputs[i])])
              << "Backward shape inconsistent with the forward shape";
          }
          if (igrad_node == nullptr) { // 获取FGradient临时创建的backward节点
            igrad_node = igrad[i].node.get();
          } else { // 逻辑(一致)检查
            CHECK(igrad_node == igrad[i].node.get());
          }
        }
      }
      CHECK(igrad_node != nullptr) // 非空检查
        << "Cannot find matching backward op for " << inode.source->attrs.name;
      /* infer backward节点输入梯度(ograd)的shape */
      for (size_t i = 0; i < igrad_node->inputs.size(); ++i) {
        const NodeEntry& e = igrad_node->inputs[i];
        if (e.node == nullptr) { // 当前输入为梯度ograd
          uint32_t eid = idx.entry_id(inode.inputs[i]); // 通过下标获取inode的ograd输入
          if (fis_none(rshape[eid])) { // shape未知
            // backward输入梯度的shape和forward节点输出保持一致
            rshape[eid] = rshape[idx.entry_id(inode.control_deps[0], e.index)];
          } // 此处也可以加一致性检查
        }
      }
    } else { // forward infer
      DispatchMode* dispatch_mode = nullptr;
      bool forward_known = true; // 是否有输入or输出shape未知
      ishape.resize(num_inputs, empty_val); // 输入shapes
      for (uint32_t i = 0; i < ishape.size(); ++i) {
        ishape[i] = rshape[idx.entry_id(inode.inputs[i])]; // 获取输入shape
        if (fis_none(ishape[i])) forward_known = false;
      }
      oshape.resize(num_outputs, empty_val); // 输出shapes
      for (uint32_t i = 0; i < oshape.size(); ++i) {
        oshape[i] = rshape[idx.entry_id(nid, i)]; // 获取输出shape
        if (fis_none(oshape[i])) forward_known = false;
      }
      if (dispatch_mode_name != nullptr) { // infer stype
        dispatch_mode = &dispatch_modes[nid]; // 获取节点dispatch mode
        if (dispatch_modes[nid] == DispatchMode::kUndefined) forward_known = false;
      }
      
      auto finfer = finfer_shape.get(inode.source->op(), fdefault);
      if (!forward_known) { // 需要infer shape
        if (finfer != nullptr) {
          try { // 调用op的infer shape函数
            forward_known = ApplyOpInferAttr(ret, finfer, inode.source->attrs,
                                             nid, &ishape, &oshape, dispatch_mode);
          } catch (const std::exception& e) {
            throw dmlc::Error("Error in operator " + inode.source->attrs.name + ": " + e.what());
          }
        } else {
          CHECK(!last_iter)
              << "Attribute " << infer_name
              << " is not registered by op " << inode.source->op()->name
              << " we are not able to complete the inference because of this";
        }
      }
      for (uint32_t i = 0; i < num_inputs; ++i) { // 更新输入shape
        rshape[idx.entry_id(inode.inputs[i])] = ishape[i];
      }
      for (uint32_t i = 0; i < num_outputs; ++i) { // 更新输出shape
        rshape[idx.entry_id(nid, i)] = oshape[i];
      }
    }
  };
 
  size_t last_num_unknown;
  size_t num_unknown_dispatch_mode = dispatch_mode_name ? node_end - node_start : 0;
  size_t num_unknown_entry_attr = entry_end - entry_start;
  size_t num_unknown = num_unknown_entry_attr + num_unknown_dispatch_mode;
  int i = 0;

  size_t num_unknown = rshape.size();
  int i = 0;
  do { // 迭代直到无未知shape 或者 已经收敛(无法infer出更多shape)
    if (i % 2 == 0) { // forward inference：正向(后序)遍历
      for (uint32_t nid = 0; nid < idx.num_nodes(); ++nid) {
        infer_step(nid, false);
      }
    } else { // backward inference：反向(前序)遍历
      for (uint32_t i = idx.num_nodes(); i != 0; --i) {
        infer_step(i - 1, false);
      }
    }
    last_num_unknown = num_unknown;
    num_unknown = 0; // 收集本轮infer后，还有多少个未知shape
    for (size_t j = entry_start; j < entry_end; ++j) {
      if (fis_none(rshape[j])) { ++num_unknown; }
    }
    if (dispatch_mode_name) { // infer stype
      for (size_t i = node_start; i < node_end; i++) {
        if (dispatch_modes[i] == DispatchMode::kUndefined) ++num_unknown;
      }
    }
    ++i;
  } while (num_unknown > 0 && last_num_unknown > num_unknown);

  ret.attrs[attr_name] = std::make_shared<any>(std::move(rshape));
  if (dispatch_mode_name) { // infer stype
    ret.attrs[dispatch_mode_name] = std::make_shared<any>(std::move(dispatch_modes));
  }
  ret.attrs[unknown_name] = std::make_shared<any>(num_unknown); // 有多少未知shape
  return std::move(ret);
}
```
## Infer函数
```c++
...
.set_attr<mxnet::FInferShape>("FInferShape", ElemwiseShape<2, 1>)
.set_attr<nnvm::FInferType>("FInferType", ElemwiseType<2, 1>)
.set_attr<FInferStorageType>("FInferStorageType", IdentityAttrLikeRhsStorageType) 
...
```
