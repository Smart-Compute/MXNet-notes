## DataBatch
一批样本；
```c++
 struct DataBatch {
   std::vector<NDArray> data;   // 样本数据
   std::vector<uint64_t> index; // 样本ID
   std::string extra_data; /* extra data to be fed to the network */
   int num_batch_padd;     /* 补齐的样本数 */
 };
```
## PrefetcherParam
支持数据类型设置、支持prefetch数设置；
```c++
 struct PrefetcherParam : public dmlc::Parameter<PrefetcherParam> {
   enum CtxType { kGPU = 0, kCPU};
   size_t prefetch_buffer; /*! \brief number of prefetched batches */
   int ctx; /*! \brief Context data loader optimized for */
   dmlc::optional<int> dtype; /*! \brief data type */
       
   // declare parameters
   DMLC_DECLARE_PARAMETER(PrefetcherParam) {
     DMLC_DECLARE_FIELD(prefetch_buffer).set_default(4)
         .describe("Maximum number of batches to prefetch.");
     DMLC_DECLARE_FIELD(ctx).set_default(kGPU) // 似乎没用到
         .add_enum("cpu", kCPU)
         .add_enum("gpu", kGPU)
         .describe("Context data loader optimized for.");
     DMLC_DECLARE_FIELD(dtype)
       .add_enum("float32", mshadow::kFloat32)
       .add_enum("float64", mshadow::kFloat64)
       .add_enum("float16", mshadow::kFloat16)
       .add_enum("int64", mshadow::kInt64)
       .add_enum("int32", mshadow::kInt32)
       .add_enum("uint8", mshadow::kUint8) 
       .add_enum("int8", mshadow::kInt8)
       .set_default(dmlc::optional<int>())
       .describe("Output data type. ``None`` means no change.");
   }
 };
```
## PrefetcherIter
* 封装TBlobBatch的dense迭代器，实现线程化迭代装载DataBatch，缓冲队列默认16；
* 支持prefetch延迟回收DataBatch，可设置最大prefetch数，达限时等待最早返回的DataBatch可释放；
```c++
 class PrefetcherIter : public IIterator<DataBatch> {
  public:
   explicit PrefetcherIter(IIterator<TBlobBatch>* base)
       : loader_(base), out_(nullptr) {}
 
   ~PrefetcherIter() {
     while (recycle_queue_.size() != 0) {
       DataBatch *batch = recycle_queue_.front();
       recycle_queue_.pop();
       delete batch;
     }
     delete out_;
     iter.Destroy();
   }
 
   void InitParams(const std::vector<std::pair<std::string, std::string> >& kwargs) {
     std::vector<std::pair<std::string, std::string> > kwargs_left;
     kwargs_left = param_.InitAllowUnknown(kwargs);
     const int kMaxPrefetchBuffer = 16; // threadediter缓存队列大小
     iter.set_max_capacity(kMaxPrefetchBuffer);
   }
 
   virtual void Init(const std::vector<std::pair<std::string, std::string> >& kwargs) {
     InitParams(kwargs);
     // use the kwarg to init batch loader
     loader_->Init(kwargs);
     iter.Init([this](DataBatch **dptr) {
         if (!loader_->Next()) return false;
         const TBlobBatch& batch = loader_->Value();
         if (*dptr == nullptr) { // allocate databatch
           *dptr = new DataBatch();
           (*dptr)->num_batch_padd = batch.num_batch_padd;
           (*dptr)->data.resize(batch.data.size());
           (*dptr)->index.resize(batch.batch_size);
           for (size_t i = 0; i < batch.data.size(); ++i) {
             auto dtype = param_.dtype // 设置错误会报类型不匹配错误
                              ? param_.dtype.value()
                              : batch.data[i].type_flag_;
             (*dptr)->data.at(i) = NDArray(batch.data[i].shape_,  // 默认存储
                                           Context::CPU(), false, // param_.ctx不生效？
                                           dtype);
           }
         }
         CHECK(batch.data.size() == (*dptr)->data.size());
         // copy data over
         for (size_t i = 0; i < batch.data.size(); ++i) {
           CHECK_EQ((*dptr)->data.at(i).shape(), batch.data[i].shape_);
           MSHADOW_TYPE_SWITCH(batch.data[i].type_flag_, DType, {
               mshadow::Copy(((*dptr)->data)[i].data().FlatTo2D<cpu, DType>(),
                         batch.data[i].FlatTo2D<cpu, DType>()); // 隐含dtype匹配检查
           });
           (*dptr)->num_batch_padd = batch.num_batch_padd; // padding数
         }
         if (batch.inst_index) { // 拷贝样本ID: unsigned => uint64_t
           std::copy(batch.inst_index,
                     batch.inst_index + batch.batch_size,
                     (*dptr)->index.begin());
         }
        return true;
       },
       [this]() { loader_->BeforeFirst(); });
   }
 
   virtual void BeforeFirst(void) { iter.BeforeFirst(); }
 
   virtual bool Next(void) { // 支持延迟回收
     if (out_ != nullptr) {  // 先加入待回收队列
       recycle_queue_.push(out_); out_ = nullptr;
     }
     // do recycle：当待回收的DataBatch太多时，等待回收最早的DataBatch
     if (recycle_queue_.size() == param_.prefetch_buffer) { // pending达限
       DataBatch *old_batch = recycle_queue_.front();
       // can be more efficient on engine
       for (NDArray& arr : old_batch->data) {
         arr.WaitToWrite();
       }
       recycle_queue_.pop();
       iter.Recycle(&old_batch); // 回收DataBatch
     }
     return iter.Next(&out_);
   }
   virtual const DataBatch &Value(void) const { return *out_; }
 
  protected:
   PrefetcherParam param_;
   dmlc::ThreadedIter<DataBatch> iter; /* 封装loader_实现线程化装载数据 */
   std::unique_ptr<IIterator<TBlobBatch> > loader_; /* 底层的TBlobBatch迭代器 */
 
  private:
   DataBatch *out_;
   std::queue<DataBatch*> recycle_queue_; /* 当前待回收的DataBatch */
 };
```
