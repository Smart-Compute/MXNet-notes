## TBlob
```
 enum TypeFlag {
   kFloat32 = 0,
   kFloat64 = 1,
   kFloat16 = 2,
   kUint8 = 3,
   kInt32 = 4,
   kInt8  = 5,
   kInt64 = 6,
 };

 /*!
  * \brief tensor blob class that can be used to hold tensor of any dimension, any device and any data type.
  */
 class TBlob {
   friend class NDArray;
  public:
   void *dptr_;          /*! \brief pointer to the data */
   mxnet::TShape shape_; /*! \brief shape of the tensor */
   int type_flag_;       /*! \brief type flag of the tensor blob */

   TBlob(void *dptr, const mxnet::TShape &shape, int dev_mask, int type_flag, int dev_id = -1)
       : dptr_(dptr), shape_(shape), type_flag_(type_flag) {
     SetDLTensor(dev_mask, dev_id);
   }

   template<typename Device, int dim, typename DType>
   inline TBlob &operator=(const mshadow::Tensor<Device, dim, DType> &src) {
     dptr_ = src.dptr_;
     shape_ = src.shape_;
     type_flag_ = mshadow::DataType<DType>::kFlag;
     SetDLTensor(Device::kDevMask, -1);
     return *this;
   }

   inline TBlob reshape(const mxnet::TShape& shape) const;

   inline int ndim(void) const { return shape_.ndim(); }
   inline index_t size(index_t idx) const { return shape_[idx]; }
   inline int dev_mask() const { return dltensor_.ctx.device_type; }
   inline int dev_id() const { return dltensor_.ctx.device_id; }
   inline const DLTensor& dltensor() const { return dltensor_; }

   template<typename DType>
   inline DType* dptr() const {
     CHECK(mshadow::DataType<DType>::kFlag == type_flag_)
       << "TBlob.get_with_shape: data type do not match specified type."
       << "Expected: " << type_flag_ << " v.s. given " << mshadow::DataType<DType>::kFlag;
     return static_cast<DType*>(dptr_);
   }

   template<typename Device, int dim, typename DType>
   inline mshadow::Tensor<Device, dim, DType> get_with_shape(
       const mshadow::Shape<dim> &shape, mshadow::Stream<Device> *stream = NULL) const {
     CHECK(Device::kDevMask == this->dev_mask()) << "TBlob.get: device type do not match specified type";
     CHECK_EQ(this->CheckContiguous(), true) << "TBlob.get_reshape: must be contiguous";
     CHECK_EQ(this->shape_.Size(), static_cast<size_t>(shape.Size()))
       << "TBlob.get_with_shape: new and old shape do not match total elements";
     return mshadow::Tensor<Device, dim, DType>(dptr<DType>(), shape, shape[dim - 1], stream);
   }

   inline void SetDLTensor(int dev_mask, int dev_id) {
     dltensor_.data = dptr_;
     dltensor_.ctx = DLContext{static_cast<DLDeviceType>(dev_mask), dev_id};
     dltensor_.ndim = shape_.ndim();
     dltensor_.dtype = DTypeTransform(type_flag_);
     dltensor_.shape = shape_.data();
     dltensor_.strides = nullptr;
     dltensor_.byte_offset = 0;
   }
 
  private:
   /*! \brief corresponding DLTensor of this TBlob */
   DLTensor dltensor_;
 };
```
