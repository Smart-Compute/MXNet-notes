## Exp
```
 namespace type {
   const int kRValue = 0;
   const int kMapper = 1;
   const int kChainer = 3;
   const int kComplex = 7;
 }

 template<typename SubType, typename DType, int exp_type>
 struct Exp { /* base class for expression */
  public:
   inline const SubType& self(void) const { return *static_cast<const SubType*>(this); }
   inline SubType* ptrself(void) { return static_cast<SubType*>(this); }
 };
 
 template<typename Container, typename DType>
 class RValueExp: public Exp<Container, DType, type::kRValue> { ... };

 template<typename Container, typename Device, int dimension, typename DType>
 struct TRValue: public expr::RValueExp<Container, DType> { }; // Tensor RValue
```
## Tensor
* 对tensor进行抽象，dptr_存储数据，下标越小维度越高(如：x，y，z)；
* 提供FlatTo1D/FlatTo2D、对最高维取下标/Slice等操作；
* 支持sse2等存储空间补齐；
```
 enum PacketArch {
   kPlain,
   kSSE2,
 };
 template<PacketArch Arch>
 struct AlignBytes { // 默认16字节对齐(2<<4)
   static const index_t value = 4;
 };

 template<typename Device, int dimension,
          typename DType MSHADOW_DEFAULT_DTYPE>
 struct Tensor: public TRValue<Tensor<Device, dimension, DType>,
                               Device, dimension, DType> {
  public:
   static const bool kDevCPU = Device::kDevCPU; /*! \brief whether current type lies in cpu */
   static const int  kSubdim = dimension - 1;
   
   DType *dptr_ = nullptr;
   Shape<dimension> shape_;
   /*
    * 当开启MSHADOW_ALLOC_PAD时，对最低维度占用存储空间进行padding补齐(16字节对齐)；
    * stride_表示最低维度占用存储空间能存储的DType元素个数；(无补齐时，为最低维度大小；有补齐时，为补齐后的大小)
    * 要求：16 % sizeof(DType) == 0 || sizeof(DType) % 16 == 0；(即：1、2、4、8、16、32等)
    */
   index_t stride_;
   Stream<Device> *stream_;

   MSHADOW_XINLINE Tensor(void) : stream_(NULL) {}
   MSHADOW_XINLINE Tensor(DType *dptr, const Shape<dimension> &shape)
       : dptr_(dptr), shape_(shape), stride_(shape[kSubdim]), stream_(NULL) {}
   MSHADOW_XINLINE Tensor(DType *dptr,
                          const Shape<dimension> &shape,
                          index_t stride, Stream<Device> *stream)
       : dptr_(dptr), shape_(shape), stride_(stride), stream_(stream) {}

   MSHADOW_XINLINE bool CheckContiguous(void) const { // 元素存储是否严格连续(即无补齐空白空间)
     return this->shape_[dimension - 1] == stride_;
   }

   template<int startdim>
   MSHADOW_XINLINE index_t MemSize(void) const {
     index_t memsz = this->stride_; // 初始值为stride_
     #pragma unroll
     for (int i = startdim; i < kSubdim; ++i) { memsz *= this->shape_[i]; }
     return memsz;
   }
   MSHADOW_XINLINE index_t MSize(void) const { return this->MemSize<0>(); }

   MSHADOW_XINLINE index_t size(index_t idx) const { return shape_[idx]; } /* 下标越小维度越高 */

   MSHADOW_XINLINE Tensor<Device, 1, DType> FlatTo1D(void) const;
   MSHADOW_XINLINE Tensor<Device, 2, DType> FlatTo2D(void) const;

   MSHADOW_XINLINE Tensor<Device, kSubdim, DType> operator[](index_t idx) const {
     return Tensor<Device, kSubdim, DType>(dptr_ + this->MemSize<1>() * idx, /* 定位内存起始位置 */
                /* SubShape：去掉最高维；*/  shape_.SubShape(), stride_, stream_);
   }
   MSHADOW_XINLINE Tensor<Device, dimension, DType>
   Slice(index_t begin, index_t end) const { // 对最高维度切割
     Shape<dimension> s = this->shape_; s[0] = end - begin;
     return Tensor<Device, dimension, DType>(dptr_ + this->MemSize<1>() * begin,
                                             s, stride_, stream_);
   }

   inline Tensor<Device, dimension, DType> &operator=(const Tensor<Device, dimension, DType> &exp);

   template<typename E, int etype>
   inline Tensor<Device, dimension, DType> &operator=(const expr::Exp<E, DType, etype> &exp) {
     return this->__assign(exp);
   }
   inline Tensor<Device, dimension, DType> &operator=(const DType &exp) {
     return this->__assign(exp);
   }
};
```
## TensorContainer
TensorContainer封装2维存储tensor；
```
 template<typename Device, int dimension, typename DType = default_real_t>
 class TensorContainer: public Tensor<Device, dimension, DType> {
  public:
    explicit TensorContainer(bool pad = MSHADOW_ALLOC_PAD) {
     this->pad_ = pad;
     this->dptr_ = data_.dptr_ = NULL;
     this->shape_[0] = 0;
     this->stride_ = 0;
     this->data_.stride_ = 0;
     this->data_.shape_[0] = 0;
   }
   explicit TensorContainer(const Shape<dimension> &shape, DType initv) {
     this->pad_ = MSHADOW_ALLOC_PAD;
     data_.dptr_ = NULL;
     this->AllocByShape(shape);
     (*this) = initv;
   }
   TensorContainer(const TensorContainer<Device, dimension, DType> &src)
       : pad_(src.pad_) {
     this->dptr_ = data_.dptr_ = NULL;
     this->shape_[0] = 0;
     this->stride_ = 0;
     this->data_.stride_ = 0;
     this->data_.shape_[0] = 0;
     this->stream_ = src.stream_;
     if (src.dptr_ != NULL) {
       this->AllocByShape(src.shape_);
       mshadow::Copy(*this, src, this->stream_);
     }
   }
   ~TensorContainer(void) MSHADOW_THROW_EXCEPTION {
     this->Release();
   }

   inline void Resize(const Shape<dimension> &shape) {
     Shape<2> s2 = shape.FlatTo2D();
     if (s2.shape_[1] > data_.stride_ || s2.shape_[0] > data_.size(0)) {
       this->AllocByShape(shape);
     } else { // 存储空间满足需求，不需要重新分配，可能有存储空间浪费
       this->shape_ = shape;
       if (this->pad_) { // 可能stride_不是最优
         this->stride_ = data_.stride_;
       } else { // 紧密(连续)存储
         this->stride_ = s2.shape_[1];
       }
     }
   }

   inline TensorContainer &operator=
   (const TensorContainer<Device, dimension, DType> &src) {
     this->pad_ = src.pad_;
     this->stream_ = src.stream_;
     if (src.dptr_ != NULL) {
       this->Resize(src.shape_); // 分配空间
       mshadow::Copy(*this, src, this->stream_); // 拷贝数据
     }
     return *this;
   }

   template<typename TStream> inline void SaveBinary(TStream &fo) const;
   template<typename TStream> inline void LoadBinary(TStream &fi);

   inline void Release(void) {
     if (data_.dptr_ != NULL) {
       this->shape_[0] = 0;
       this->stride_ = 0;
       this->data_.stride_ = 0;
       this->data_.shape_[0] = 0;
       try {
         mshadow::FreeSpace(&data_);
       } catch (const dmlc::Error &e) {
         this->dptr_ = data_.dptr_ = NULL;
         throw e;
       }
       this->dptr_ = data_.dptr_ = NULL;
     }
   }

  private:
   bool pad_;                      /* 分配存储时，是否补齐 */
   Tensor<Device, 2, DType> data_; /* 真正存储数据的底层tensor */
 
   inline void AllocByShape(const Shape<dimension>& shape) {
     if (data_.dptr_ != NULL) this->Release();
     data_.shape_ = shape.FlatTo2D();   // 压缩成两维tensor
     mshadow::AllocSpace(&data_, pad_); // 为tensor分配存储空间，考虑padding(最低维度空间)
     this->dptr_ = data_.dptr_;         // 用封装的两维tensor，初始化基类tensor
     this->shape_ = shape;
     if (this->pad_) {
       this->stride_ = data_.stride_;   // 对最低维度空间padding补齐后能存储的元素个数
     } else {
       this->stride_ = data_.size(1);
     }
   }
 };

 inline void* AlignedMallocPitch(size_t *out_pitch,  // 空间补齐后的元素大小
                                 size_t lspace,      // 元素大小
                                 size_t num_line);   // 元素个数

 template<int dim, typename DType>
 inline void AllocSpace(Tensor<cpu, dim, DType> *obj, bool pad) {
   size_t pitch;
   void *dptr;
   if (pad) { // 需要补齐
     dptr = packet::AlignedMallocPitch
         (&pitch, obj->size(dim - 1) * sizeof(DType), obj->shape_.FlatTo2D()[0]);
     obj->stride_ = static_cast<index_t>(pitch / sizeof(DType)); // 计算补齐后空间能存储的元素个数
   } else { // 紧密存储，无需补齐
     obj->stride_ = obj->size(dim - 1);
     dptr = packet::AlignedMallocPitch
         (&pitch, obj->shape_.Size() * sizeof(DType), 1);
   }
   obj->dptr_ = reinterpret_cast<DType*>(dptr);
 }   
```
