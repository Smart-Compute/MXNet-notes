## SparseBatchLoader
* 对sparse样本迭代器进行封装，提供按batch迭代的功能，提供round读取；
* 底层为batch分配存储空间；
* ResizeBuffer()看起来有问题：拷贝两次、内存泄露；
```
 size_t num_aux_data(NDArrayStorageType stype) { // 除data tensor外，辅助tensor个数
   size_t num = 0;
   switch (stype) {
     case kDefaultStorage: num = 0; break; // dense存储无需辅助tensor
     case kCSRStorage: num = 2; break; // CSR存储需要两个辅助tensor：特征ID和样本偏移位置
     case kRowSparseStorage: num = 1; break; // RowSparse需要一个辅助tensor：特征ID
      default: LOG(FATAL) << "Unknown storage type" << stype; break;
   }
   return num;
 }

 class SparseBatchLoader : public BatchLoader, public SparseIIterator<TBlobBatch> {
  public:
   explicit SparseBatchLoader(SparseIIterator<DataInst> *base):
       BatchLoader(base), sparse_base_(base) {}
 
   virtual ~SparseBatchLoader(void) {}
 
   inline void Init(const std::vector<std::pair<std::string, std::string> >& kwargs) {
     BatchLoader::Init(kwargs);
     data_stype_ = sparse_base_->GetStorageType(true);   // 特征存储格式
     label_stype_ = sparse_base_->GetStorageType(false); // label存储格式
     if (param_.round_batch == 0) { // 必须是round读取
       LOG(FATAL) << "sparse batch loader doesn't support round_batch == false yet";
     }
   }
 
   virtual void BeforeFirst(void) { BatchLoader::BeforeFirst(); }
 
   virtual bool Next(void) {
     out_.num_batch_padd = 0;
     out_.batch_size = param_.batch_size;
     this->head_ = 0;
     // 上次调用已经迭代完毕且round补齐，当再次调用BeforeFirst()时，放行继续读取
     if (num_overflow_ != 0) return false;
     size_t top = 0;
     offsets_.clear(); // 样本偏移位置
     while (sparse_base_->Next()) {
       const DataInst& inst = sparse_base_->Value();
       // initialize the data buffer, only called once
       if (data_.size() == 0) this->InitData(inst); // 初始化
       // initialize the number of elements in each buffer, called once per batch
       if (offsets_.size() == 0) offsets_.resize(inst.data.size(), 0); // 初始化为0
       CopyData(inst, top); // 拷贝样本到batch存储空间
       if (++top >= param_.batch_size) { // batch读满返回
         SetOutputShape();
         return true;
       }
     }
     // 样本迭代完毕
     if (top != 0) { // 已读入部分样本
       CHECK_NE(param_.round_batch, 0) // 只支持round模式，需要从头读入样本补齐
         << "round_batch = False is not supported for sparse data iterator";
       num_overflow_ = 0;
       sparse_base_->BeforeFirst();
       for (; top < param_.batch_size; ++top, ++num_overflow_) {
         CHECK(sparse_base_->Next()) << "number of input must be bigger than batch size";
         const DataInst& inst = sparse_base_->Value();
         CopyData(inst, top); // copy data
       }
       SetOutputShape();
       out_.num_batch_padd = num_overflow_; // 上面有check确保不会出现batch没填满的极端情况
       return true;
     }
     return false; // 无样本读入
   }
 
   virtual const TBlobBatch &Value(void) const { return BatchLoader::Value(); }
 
   virtual const NDArrayStorageType GetStorageType(bool is_data) const {
     return sparse_base_->GetStorageType(is_data);
   }
 
   virtual const mxnet::TShape GetShape(bool is_data) const {
     mxnet::TShape inst_shape = sparse_base_->GetShape(is_data);
     std::vector<index_t> shape_vec;
     shape_vec.push_back(param_.batch_size); // 增加top维度：表示当前batch中，样本的下标；
     for (index_t dim = 0; dim < inst_shape.ndim(); ++dim) {
       shape_vec.push_back(inst_shape[dim]);
     }
     return mxnet::TShape(shape_vec.begin(), shape_vec.end());
   }
 
  private:
   SparseIIterator<DataInst> *sparse_base_; /*! \brief base sparse iterator */
   NDArrayStorageType data_stype_;          /*! \brief data storage type */
   NDArrayStorageType label_stype_;         /*! \brief data label type */
   std::vector<size_t> offsets_;            /*! \brief tensor offsets for slicing */
   std::vector<int> dtypes_;                /*! \brief tensor dtypes */
   /*! \brief whether the offset correspond to an indptr array */
   std::vector<bool> indptr_;
 
   // check whether ith position is the indptr tensor for a CSR tensor
   inline bool IsIndPtr(size_t i) {
     auto data_num_aux = num_aux_data(data_stype_);
     auto label_num_aux = num_aux_data(label_stype_);
     auto label_indptr_offset = data_num_aux + 1 + label_num_aux;
     // data indptr：CSR存储时，indptr放在最末尾；
     if (i == data_num_aux && data_stype_ == kCSRStorage) {
       return true;
     }
     // label indptr：CSR存储时，indptr放在最末尾；
     if (i == label_indptr_offset && label_stype_ == kCSRStorage &&
         data_stype_ == kCSRStorage) { // 此处为何多了data_stype_的检测？
       return true;
     }
     return false;
   }
 
   // initialize the data holder by using from the batch
   inline void InitData(const DataInst& first_inst) {
     CHECK(data_stype_ == kCSRStorage || label_stype_ == kCSRStorage);
     out_.data.clear(); // 清空TBlobBatch
     data_.clear();     // 清空存储空间
     offsets_.clear();  // 清空样本offsets
     indptr_.clear();   // 清空indptr标记
 
     // num_arrays is the number of arrays in inputs
     // if both data and label are in the csr format,
     // num_arrays will be 3 + 3 = 6.
     size_t num_arrays = first_inst.data.size(); // 总tensor数(data+label)
     data_.resize(num_arrays);          // 底层存储tensor
     offsets_.resize(num_arrays, 0);    // 设置样本偏移位置为0
     indptr_.resize(num_arrays, false); // 默认都为false
     dtypes_.resize(num_arrays);        // tensor数据类型
     out_.data.resize(num_arrays);      // 轻量级tensor
     // tensor存储空间大小(估算)
     std::vector<size_t> buff_sizes(num_arrays, 0);
     // estimate the memory required for a batch
     for (size_t i = 0; i < num_arrays; ++i) {
       if (IsIndPtr(i)) {
         buff_sizes[i] = param_.batch_size + 1; // 额外多了个end
         indptr_[i] = true;
       } else {
         // estimated the size for the whole batch based on the first instance
         buff_sizes[i] = first_inst.data[i].Size() * param_.batch_size;
         indptr_[i] = false;
       }
       dtypes_[i] = first_inst.data[i].type_flag_; // 存储数据类型
     }
 
     CHECK_EQ(buff_sizes[0], buff_sizes[1]); // 简单校验
     for (size_t i = 0; i < num_arrays; ++i) {
       // 为batch分配存储空间
       mxnet::TShape dst_shape(mshadow::Shape1(buff_sizes[i]));
       data_[i].resize(mshadow::Shape1(buff_sizes[i]), dtypes_[i]);
       CHECK(data_[i].dptr_ != nullptr);
     }
   }
 
   /* \brief set the shape of the outputs based on actual shapes */
   inline void SetOutputShape() {
     for (size_t i = 0; i < out_.data.size(); i++) { // 对外封装为一维tensor
       out_.data[i] = TBlob(data_[i].dptr_, mshadow::Shape1(offsets_[i]),
                            Context::kCPU, dtypes_[i]);
     }
   }
 
   /* \brief increase the size of i-th data buffer by a factor of 2, while retaining the content */
   inline void ResizeBuffer(size_t src_size, size_t i) {
     MSHADOW_TYPE_SWITCH(data_[i].type_flag_, DType, {
       TBlobContainer temp;
       temp.resize(mshadow::Shape1(src_size), dtypes_[i]);
       mshadow::Copy(temp.get<cpu, 1, DType>(), data_[i].get<cpu, 1, DType>().Slice(0, src_size));
       // increase the size of space exponentially
       size_t capacity = data_[i].Size();
       capacity = capacity * 2 + 1;
       data_[i] = TBlobContainer(); // TBlobContainer无定义良好的赋值函数，会有内存泄露
       data_[i].resize(mshadow::Shape1(capacity), dtypes_[i]);
       // copy back // 为何要先拷贝到临时空间，再拷贝回来？？
       mshadow::Copy(data_[i].get<cpu, 1, DType>().Slice(0, src_size), temp.get<cpu, 1, DType>());
     });
   }
 
   /* \brief copy the data instance to data buffer */
   void CopyData(const DataInst& inst, const size_t top) {
     int64_t unit_size = 0;
     out_.inst_index[top] = inst.index;
     for (size_t i = 0; i < inst.data.size(); ++i) {
       if (!indptr_[i]) {
         // indices and values tensor
         unit_size = inst.data[i].shape_.Size(); // data/index tensor大小相等
         MSHADOW_TYPE_SWITCH(data_[i].type_flag_, DType, {
           const size_t begin = offsets_[i];
           const size_t end = offsets_[i] + unit_size;
           size_t capacity = data_[i].Size();

           while (capacity < end) { // 空间不足
             ResizeBuffer(begin, i);
             capacity = data_[i].Size();
           }
           mshadow::Copy(data_[i].get<cpu, 1, DType>().Slice(begin, end),
                         inst.data[i].get_with_shape<cpu, 1, DType>(mshadow::Shape1(unit_size)));
         });
         offsets_[i] += unit_size; // 更新偏移位置
       } else { // indptr placeholder
         auto indptr = data_[i].get<cpu, 1, int64_t>(); // 预先分配好的，空间足够
         // initialize the first indptr, which is always 0
         if (top == 0) indptr[0] = 0;
         indptr[top + 1] = indptr[top] + unit_size; // 设置样本end偏移
         offsets_[i] = top + 2; // 更新偏移位置
       }
     }
   }
 };
```
