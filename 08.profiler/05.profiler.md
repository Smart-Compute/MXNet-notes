## DeviceStats
封装线程安全队列，收集某个设备的profile事件；
```c++
 struct DeviceStats {
   using TQueue = dmlc::moodycamel::ConcurrentQueue<ProfileStat *>;

   ~DeviceStats() {
     std::shared_ptr<TQueue> es = opr_exec_stats_;
     if (es) { // 回收队列资源
       ProfileStat *stat = nullptr;
       while (es->try_dequeue(stat)) {
         delete stat;
       }
     }
   }

   std::string dev_name_;
   std::shared_ptr<TQueue> opr_exec_stats_ = std::make_shared<TQueue>(); // profile事件队列
 };
```
## Profiler
* 使用者在代码中创建Profile事件(如：ProfileEvent)，该事件会通过AddNewProfileStat()发送到Profiler；
* Profiler为每个设备维护一个接收profile事件的队列，定期将profile事件dump到文件，并更新聚合统计量；
* Profiler额外维护了一个设备无关的profile事件接收队列；
* 使用方可以获取聚合统计量(AggregateStats)，并按table或json格式输出到ostream；
```c++
 class Profiler {
  public:
   enum ProfilerMode {
       kSymbolic = 1,
       kImperative = 2,
       kAPI = 4,
       kMemory = 8
   };
   enum ProfilerState {
       kNotRunning = 0,
       kRunning = 1
   };
  public:
   Profiler();
   virtual ~Profiler();

   /* 配置：是否开启定期dump线程、是否聚合统计profile事件 */
   void SetConfig(int mode, std::string output_filename,
                  bool continuous_dump, // 定期dump profile事件
                  float dump_period, // dump间隔
                  bool aggregate_stats); // 是否聚合profile事件

   uint64_t MSHADOW_CINLINE GetInitTime() const { return init_time_; }

   void SetState(ProfilerState state);
   inline ProfilerState GetState() const { return this->state_; }

   inline int GetMode() const { return this->mode_; }
   inline bool IsProfiling(const ProfilerMode pm) const {
     return GetState() == kRunning && (GetMode() & pm) == pm;
   }
   inline bool IsEnableOutput() const { return this->enable_output_; }

   /* 获取AggregateStats以便调用其DumpTable()/DumpJson()函数dump统计信息 */
   std::shared_ptr<AggregateStats> GetAggregateStats() const { return aggregate_stats_; }
   void set_paused(bool paused) { paused_ = paused; } // 暂停接收profile事件
   inline bool AggregateEnabled() const { return aggregate_stats_.get() != nullptr; }
   inline bool AggregateRunning() const { return GetState() == kRunning && AggregateEnabled(); }

   size_t DeviceCount() const { return cpu_num_ + gpu_num_ + 2; }
   size_t DeviceIndex(mxnet::Context::DeviceType dev_type, int32_t dev_id) { // 获取设备下标
     switch (dev_type) {
       case Context::kCPU:       return dev_id;
       case Context::kGPU:       return cpu_num_ + dev_id;
       case Context::kCPUPinned: return cpu_num_ + gpu_num_;
       case Context::kCPUShared: return cpu_num_ + gpu_num_ + 1;
       default: LOG(FATAL) << "Unknown dev_type: " << dev_type; return 0;
     }
   }
   const char *DeviceName(mxnet::Context::DeviceType dev_type, int32_t dev_id);
   const char *DeviceName(const size_t index);

   static Profiler* Get(std::shared_ptr<Profiler> *sp = nullptr); // 获取单例

   /* 从profile_stat和general_stats_获取(消费)profile事件，dump到文件，并更新统计量(aggregate_stats_) */
   void DumpProfile(bool perform_cleanup = true);

   template<typename StatType, typename SetExtraInfoFunction, typename ...Args>
   void AddNewProfileStat(SetExtraInfoFunction set_extra_info_function, Args... args) {
     if (!paused_) { // 创建并添加profile事件
       std::unique_ptr<StatType> stat = CreateProfileStat<StatType>(args...);
       set_extra_info_function(stat.get());
       AddProfileStat(&stat);
     }
   }
 
  private:
   template<typename StatType, typename ...Args>
   static std::unique_ptr<typename std::enable_if<std::is_base_of<ProfileStat, StatType>::value,
     StatType>::type> CreateProfileStat(Args... args) { // 创建profile事件
     return std::unique_ptr<StatType>(new StatType(args...));
   }
   template<typename StatType>
   inline void AddProfileStat(std::unique_ptr<StatType> *stat) { // 添加profile事件
     /* 添加到general_stats，针对ProfileOperator有特化实现 */
     general_stats_.opr_exec_stats_->enqueue(stat->release());
   }

   void EmitPid(std::ostream *os, const std::string& name, size_t pid);
   /* 开启or关闭定期dump线程 */
   void SetContinuousProfileDump(bool continuous_dump, float delay_in_seconds);

   std::recursive_mutex m_;
   ProfilerState state_;
   volatile bool enable_output_;
   int mode_ = kSymbolic | kAPI | kMemory;
   std::string filename_ = "profile.json";
   std::unique_ptr<DeviceStats[]> profile_stat; // 收集统计各设备上执行的op：cpu_num_ + gpu_num_ + 2；
   DeviceStats  general_stats_; // 与具体设备无关的统计
   std::unordered_map<std::string, size_t> category_to_pid_; // 与设备无关的profile，pid是由其cate取hash得到的
   unsigned int cpu_num_;
   unsigned int gpu_num_;
   uint64_t init_time_;
   volatile bool continuous_dump_ = false;
   volatile uint64_t num_records_emitted_ = 0;
   volatile uint64_t profile_dump_count_;
   volatile bool paused_ = false;
   std::shared_ptr<AggregateStats> aggregate_stats_ = nullptr;
   std::shared_ptr<dmlc::ThreadGroup> thread_group_ = std::make_shared<dmlc::ThreadGroup>();
   std::unordered_set<uint32_t> process_ids_;
 };
 
 template<>
 inline void Profiler::AddProfileStat<ProfileOperator::OprExecStat>(
   std::unique_ptr<ProfileOperator::OprExecStat> *opr_stat) { // 针对ProfileOperator的特化
   const size_t idx = DeviceIndex((*opr_stat)->dev_type_, (*opr_stat)->dev_id_);
   CHECK_LT(idx, DeviceCount());
   DeviceStats& dev_stat = profile_stat[idx];
   dev_stat.opr_exec_stats_->enqueue((*opr_stat).release()); // 添加到具体的设备队列
 }
```
