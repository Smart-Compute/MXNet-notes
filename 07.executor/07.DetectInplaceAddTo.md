## DetectInplaceAddTo
* 自动优化_grad_add；
* 对于lhs和output的sid一致、rhs op只有一个引用、(后序遍历)lhs先于rhs执行时，可开启kAddTo优化；
* kAddTo优化暂时只支持dense存储格式；
```c++
Graph DetectInplaceAddTo(Graph g) {
  nnvm::StorageVector storage_id =
      g.MoveCopyAttr<nnvm::StorageVector>("storage_id");
  std::vector<int> storage_inplace_index =
      g.MoveCopyAttr<std::vector<int> >("storage_inplace_index");
  static const Op* ewise_plus_op = Op::Get("_grad_add"); // 针对梯度累加生效
  static const Op* transpose_op = Op::Get("transpose");  // transpose不支持kAddTo
  auto& idx = g.indexed_graph();

  std::vector<int> ref_count(idx.num_node_entries(), 0);
  std::vector<int> addto_entry(idx.num_node_entries(), 0);
  std::vector<int> skip_plus_node(idx.num_nodes(), 0);
  /* 持有计算图ouputs的引用；每个op持有其inputs的引用； */
  for (auto& e : idx.outputs()) { ++ref_count[idx.entry_id(e)]; }
  for (uint32_t nid = 0; nid < idx.num_nodes(); ++nid) {
    for (auto &e : idx[nid].inputs) { ++ref_count[idx.entry_id(e)]; }
  }

  for (uint32_t nid = 0; nid < idx.num_nodes(); ++nid) {
    const auto& inode = idx[nid];
    if (inode.source->op() != ewise_plus_op) continue; // kAddTo只在_grad_add时生效
    int sid = storage_id[idx.entry_id(inode.inputs[0])];
    if (sid != storage_id[idx.entry_id(nid, 0)]) continue; // kAddTo要求lhs和output的sid一样
    if (idx[inode.inputs[0].node_id].source->is_variable()) continue; // lhs是var，无法写入
    if (idx[inode.inputs[1].node_id].source->is_variable()) continue; // rhs是var，不支持kAddTo
    /* transpose do not support kAddTo */
    if (idx[inode.inputs[1].node_id].source->op() == transpose_op) continue;
    uint32_t eid_rhs  = idx.entry_id(inode.inputs[1]); 
    if (ref_count[eid_rhs] != 1) continue; // rhs被多个op引用，无法支持kAddTo
    if (inode.inputs[0].node_id >= inode.inputs[1].node_id) continue; // kAddTo要求lhs先于rhs执行
    // TODO(haibin) support inplace addto for Dynamic Storage
    if (storage_id[eid_rhs] == kDynamicStorageID) continue; // 只支持dense存储的rhs
    CHECK_NE(storage_id[eid_rhs], sid); // lhs和rhs的sid检查
    storage_id[eid_rhs] = sid; // 设置rhs的sid
    addto_entry[eid_rhs] = 1;  // 设置rhs op使用kAddTo模式
    storage_inplace_index[eid_rhs] = -1; // kAddTo特殊标记
    skip_plus_node[nid] = 1;   // 当前_grad_add被rhs op的kAddTo优化替换掉
  }
 
  g.attrs["storage_id"] = std::make_shared<nnvm::any>(std::move(storage_id));
  g.attrs["storage_inplace_index"] = std::make_shared<nnvm::any>(
      std::move(storage_inplace_index));
  g.attrs["addto_entry"] = std::make_shared<nnvm::any>(std::move(addto_entry));
  g.attrs["skip_plus_node"] = std::make_shared<nnvm::any>(std::move(skip_plus_node));
  return g;
}
```
