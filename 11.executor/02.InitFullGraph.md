## InitFullGraph
* 自动生成反向传播图，把需要计算的梯度追加到前向图输出之后，返回完整的计算图；
* 因为forward的ouput在backward的output之前，所以，在生成后序遍历节点序时，forward图节点排在backward图节点之前；
* 同样，forward的输入排在backward的输入(forward output对应的grad)之前；
* 参加[gradient](https://github.com/zhuzilong-cn/MXNet-notes/blob/master/10.nnvm/07.gradient.md)；
```c++
static nnvm::NodeEntry AttrHint(nnvm::NodeEntry src, nnvm::NodeEntry like) {
  static const Op* id_like = Op::Get("_identity_with_attr_like_rhs");
  nnvm::NodePtr n = nnvm::Node::Create();
  n->attrs.op = id_like;
  n->attrs.name = src.node->attrs.name + "_id";
  n->inputs = {src, like};
  return nnvm::NodeEntry{n, 0, 0};
}

nnvm::Graph GraphExecutor::InitFullGraph(nnvm::Symbol symbol,
                                         const std::vector<OpReqType>& grad_req_types) {
  using nnvm::NodePtr;
  using nnvm::NodeEntry;
  // 输入参数symbol为forward网络
  num_forward_outputs_ = symbol.outputs.size(); // forward输出数
  num_forward_inputs_ = symbol.ListInputs(nnvm::Symbol::kAll).size(); // 网络中var节点数
 
  nnvm::Graph g;
  g.outputs = symbol.outputs; // symbol => graph
  need_grad_ = false;
  for (OpReqType req : grad_req_types) {
    if (req != kNullOp) need_grad_ = true; // 设置是否需要计算梯度
  }
  if (!need_grad_) return g; // 无需计算梯度，无需自动生成反向传播图
  for (size_t i = 0; i < g.outputs.size(); ++i) { // 每个output对应一个输入梯度
     NodeEntry ngrad(nnvm::Node::Create(), 0, 0); // 创建梯度节点，对整个计算图来讲，ngrad也是input
     head_grad_entry_.emplace_back(AttrHint(ngrad, g.outputs[i])); // 将ngrad和output关联起来
     head_grad_map_[ngrad.node.get()] = i; // 将ngrad节点指针映射为偏移位置
   }
   std::vector<NodePtr> args = symbol.ListInputs(nnvm::Symbol::kReadOnlyArgs);
   std::vector<NodeEntry> xs; // 构造需要计算梯度的input变量
   for (size_t i = 0; i < grad_req_types.size(); ++i) {
     if (grad_req_types[i] != kNullOp) { // 梯度更新方式
       xs.emplace_back(args[i]);
     }
   }
   /* 在反向传播图中引用forward节点时，是否使用镜像节点； */
   int do_mirror = dmlc::GetEnv("MXNET_BACKWARD_DO_MIRROR", 0);
   auto need_mirror = [do_mirror](const nnvm::Node& node) -> int {
     if (node.is_variable()) return 0;
     const std::string& type = node.attrs.op->name;
     if (type == "Dropout") return false;
     if (get_node_attr(node, "__force_mirroring__", false)) return true;
     if (do_mirror == 0) return false;
     if (type == "Convolution") return false;
     if (type == "FullyConnected") return false;
     if (type == "Concat") return false;
     if (type == "SoftmaxOutput") return false;
     if (type == "BatchNorm") return false;
     if (type == "CuDNNBatchNorm") return false;
     return true;
   };
   /* 支持的zero_ops，判断梯度是否全为0，第一个必须为zeros_like； */
   std::vector<const nnvm::Op*> zero_ops;
   zero_ops.push_back(nnvm::Op::Get("zeros_like"));
   zero_ops.push_back(nnvm::Op::Get("_zeros"));
   /* 自动生成反向传播图 */
   nnvm::Graph g_grad = nnvm::pass::MXGradient(
       g, symbol.outputs, xs, head_grad_entry_,
       AggregateGradient, need_mirror, nullptr,
       zero_ops, "_copy");
   CHECK_EQ(g_grad.outputs.size(), xs.size()); // 输出即为待计算的梯度
   for (const auto &e : g_grad.outputs) {
     g.outputs.push_back(e); // 把反向传播图的输出追加到forward图输出的后面
   }
   return g; // 返回完整的计算图
 }
```
