 ## Storage
```c++
 class Storage {
  public:
   struct Handle {
     void* dptr{nullptr};
     size_t size{0};
     Context ctx;
     /* IPC参数 */
     int shared_pid{-1};
     int shared_id{-1};
   };

   Handle Alloc(size_t size, Context ctx) {
     Handle hd;
     hd.size = size; hd.ctx = ctx;
     this->Alloc(&hd);
     return hd;
   }
   virtual void Alloc(Handle* handle) = 0;
   virtual void Free(Handle handle) = 0;
   virtual void DirectFree(Handle handle) = 0;
   virtual void ReleaseAll(Context ctx) = 0;
   virtual void SharedIncrementRefCount(Handle handle) = 0;

   virtual ~Storage() {}
   std::mutex& GetMutex(Context::DeviceType dev) {
     if (dev == Context::kCPU) { return cpu_mutex_; }
     else { return gpu_mutex_; }
   }

   static Storage* Get();
   static std::shared_ptr<Storage> _GetSharedRef();
 
  private:
   std::mutex cpu_mutex_;
   std::mutex gpu_mutex_;
 };
 
 std::shared_ptr<Storage> Storage::_GetSharedRef() {
 #ifdef __MXNET_JS__
   static int *q = new int();
 #endif
   static std::shared_ptr<Storage> inst(new StorageImpl());
   return inst;
 }
 Storage* Storage::Get() {
   static Storage *ptr = _GetSharedRef().get();
   return ptr;
 }
```
## StorageManager
```c++
 class StorageManager {
  public:
   virtual void Alloc(Storage::Handle* handle) = 0;
   virtual void Free(Storage::Handle handle) = 0;
   virtual void DirectFree(Storage::Handle handle) = 0;
   virtual void ReleaseAll() {}
   virtual ~StorageManager() = default;
 };

 template <class DeviceStorage>
 class NaiveStorageManager final : public StorageManager {
  public:
   NaiveStorageManager() = default;
   ~NaiveStorageManager() = default;
   void Alloc(Storage::Handle* handle) {
     DeviceStorage::Alloc(handle);
   }
   void Free(Storage::Handle handle) {
     DeviceStorage::Free(handle);
   }
   void DirectFree(Storage::Handle handle) override {
     DeviceStorage::Free(handle);
   }
  private:
   DISALLOW_COPY_AND_ASSIGN(NaiveStorageManager);
 };
```
## CPUDeviceStorage
```c++
 class CPUDeviceStorage {
  public:
   inline static void Alloc(Storage::Handle* handle) {
     handle->dptr = nullptr;
     const size_t size = handle->size;
     if (size == 0) return;
     int ret = posix_memalign(&handle->dptr, alignment_, size);
     if (ret != 0) LOG(FATAL) << "Failed to allocate CPU Memory"; 
   }
   inline static void Free(Storage::Handle handle) { free(handle.dptr); }
             
  private:
 #if MXNET_USE_MKLDNN == 1
   static constexpr size_t alignment_ = kMKLDNNAlign; // 64
 #else
   static constexpr size_t alignment_ = 16;
 #endif      
 };
```
## StorageImpl
```c++
 class StorageImpl : public Storage {
  public:
   void Alloc(Handle* handle) override;
   void Free(Handle handle) override;
   void DirectFree(Handle handle) override;
   void ReleaseAll(Context ctx) override;
   void SharedIncrementRefCount(Handle handle) override;
   StorageImpl() {}
   virtual ~StorageImpl() = default;
 
  private:
   static constexpr size_t kMaxNumberOfDevices = Context::kMaxDevType + 1;
 #if MXNET_USE_CUDA
   static int num_gpu_device;
 #endif
 
   std::array<common::LazyAllocArray<storage::StorageManager>,
              kMaxNumberOfDevices> storage_managers_;
   storage::DeviceStorageProfiler profiler_;
 };

 #if MXNET_USE_CUDA
 int StorageImpl::num_gpu_device = 0;
 #endif
 
 void StorageImpl::Alloc(Storage::Handle* handle) {
   auto&& device = storage_managers_.at(handle->ctx.dev_type);
   std::shared_ptr<storage::StorageManager> manager = device.Get(
       handle->ctx.real_dev_id(), [handle]() {
         storage::StorageManager *ptr = nullptr;
         switch (handle->ctx.dev_type) {
           case Context::kCPU: { // cpu设备内存分配
             ptr = new storage::NaiveStorageManager<storage::CPUDeviceStorage>();
             break;
           }
           case Context::kCPUShared: {
 #if !defined(ANDROID) && !defined(__ANDROID__)
             ptr = new storage::CPUSharedStorageManager();
 #else
             LOG(FATAL) << "Unimplemented device";
 #endif
             break;
           }
           case Context::kCPUPinned: {
 #if MXNET_USE_CUDA
             num_gpu_device = 0;
             cudaError_t e = cudaGetDeviceCount(&num_gpu_device);
             if (e != cudaSuccess) { num_gpu_device = 0; }
             if (num_gpu_device > 0) {
               ptr = new storage::NaiveStorageManager<storage::PinnedMemoryStorage>();
             } else {
               ptr = new storage::NaiveStorageManager<storage::CPUDeviceStorage>();
             }
 #else
             ptr = new storage::NaiveStorageManager<storage::CPUDeviceStorage>();
 #endif
             break;
           }
           case Context::kGPU: {
 #if MXNET_USE_CUDA
             CUDA_CALL(cudaGetDeviceCount(&num_gpu_device));
             CHECK_GT(num_gpu_device, 0) << "GPU usage requires at least 1 GPU";
 
             const char *type = getenv("MXNET_GPU_MEM_POOL_TYPE");
             const bool default_pool = (type == nullptr);
             if (default_pool) type = "Naive";
             std::string strategy = type;
 
             if (strategy == "Round") {
               ptr = new storage::GPUPooledRoundedStorageManager(handle->ctx);
               LOG(INFO) << "Using GPUPooledRoundedStorageManager.";
             } else if (strategy == "Naive") {
               ptr = new storage::GPUPooledStorageManager(handle->ctx);
             } else if (strategy == "Unpooled") {
               ptr = new storage::NaiveStorageManager<storage::GPUDeviceStorage>();
             } else {
               LOG(FATAL) << "Unknown memory pool strategy specified: " << strategy << ".";
             }
 #else
             LOG(FATAL) << "Compile with USE_CUDA=1 to enable GPU usage";
 #endif
             break;
           }
           default: LOG(FATAL) <<  "Unimplemented device " << handle->ctx.dev_type;
         }
         return ptr;
       });
 
   manager->Alloc(handle);
   profiler_.OnAlloc(*handle);
 }
 
 void StorageImpl::Free(Storage::Handle handle) {
   if (handle.dptr == nullptr) return;
 
   const Context &ctx = handle.ctx;
   auto&& device = storage_managers_.at(ctx.dev_type);
   std::shared_ptr<storage::StorageManager> manager = device.Get(
       ctx.real_dev_id(), []() {
         LOG(FATAL) <<  "Cannot Free space to a device you have not allocated";
         return nullptr;
       });
 
   manager->Free(handle);
   profiler_.OnFree(handle);
 }
 void StorageImpl::DirectFree(Storage::Handle handle) {
   if (handle.dptr == nullptr) return;
 
   const Context &ctx = handle.ctx;
   auto&& device = storage_managers_.at(ctx.dev_type);
   std::shared_ptr<storage::StorageManager> manager = device.Get(
       ctx.real_dev_id(), []() {
         LOG(FATAL) <<  "Cannot Free space to a device you have not allocated";
         return nullptr;
       });
 
   manager->DirectFree(handle);
   profiler_.OnFree(handle);
 }
 
 void StorageImpl::ReleaseAll(Context ctx) {
   auto&& device = storage_managers_.at(ctx.dev_type);
   std::shared_ptr<storage::StorageManager> manager = device.Get(
     ctx.real_dev_id(), []() {
     LOG(FATAL) << "Cannot Free space to a device you have not allocated";
     return nullptr;
   });
   manager->ReleaseAll();
 }
 
 void StorageImpl::SharedIncrementRefCount(Storage::Handle handle) {
   CHECK_EQ(handle.ctx.dev_type, Context::kCPUShared);
   auto&& device = storage_managers_.at(Context::kCPUShared);
   auto manager = device.Get(0, []() {
       LOG(FATAL) << "Cannot increment ref count before allocating any shared memory.";
       return nullptr;
     });
 #if defined(ANDROID) || defined(__ANDROID__)
   LOG(FATAL) << "Shared memory not implemented on Android";
 #else
   dynamic_cast<storage::CPUSharedStorageManager*>(manager.get())->IncrementRefCount(handle);
 #endif
 }
```
